{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53bda619",
   "metadata": {},
   "source": [
    "# Experiments for Predicting Creative Mode of Thinking from EEG Signal\n",
    "\n",
    "Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy import signal\n",
    "import os\n",
    "import mne\n",
    "import mne_microstates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "860ecd1c",
   "metadata": {},
   "source": [
    "Loading Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('FinalProjectData/sub_02.json')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08499b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5486efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dict_raw = {}\n",
    "subject_dict_segments = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f78b8d7",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "The nature study that generated this dataset (https://www.nature.com/articles/s41598-021-81655-0) noted differences in the coverage and duration of EEG microstates, as well as the power of the upper and lower alpha band between the EEG signal between different modes of thinking. First, we will extract these features and use traditional machine learning methods to try to determine the creative mode of thinking from EEG signal\n",
    "\n",
    "### Extracting Duration and Coverage of 6 EEG Microstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c113ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(sorted(os.listdir('FinalProjectData'))[2:]):\n",
    "    f = open('FinalProjectData/' + file)\n",
    "    data = json.load(f)\n",
    "    subject_dict_raw[i] = {}\n",
    "    subject_dict_segments[i] = {}\n",
    "    for key in list(data.keys()):\n",
    "        arr = np.array(data[key])\n",
    "        subject_dict_raw[i][key] = arr\n",
    "        raw = mne.io.RawArray(arr, info = mne.create_info([str(i) for i in range(arr.shape[0])], 300, ch_types='eeg', verbose=0), verbose=0)\n",
    "        raw.set_eeg_reference('average', verbose=0)\n",
    "        raw.filter(0.2, None, verbose=0)\n",
    "        raw.pick_types(meg=False, eeg=True, verbose=0)\n",
    "        maps, segmentation = mne_microstates.segment(raw.get_data(), n_states=6, verbose=0)\n",
    "        subject_dict_segments[i][key] = segmentation\n",
    "    #     mne_microstates.plot_segmentation(segmentation[:500], raw.get_data()[:, :500], raw.times[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd37e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "microstate_rel_frequency = np.zeros((28, 4, 6, 1))\n",
    "\n",
    "for subject in list(subject_dict_segments.keys()):\n",
    "    for key in subject_dict_segments[subject].keys():\n",
    "        if 'rest' in key:\n",
    "            i=0\n",
    "        elif 'idea generation' in key:\n",
    "            i=1\n",
    "        elif 'evolution' in key:\n",
    "            i=2\n",
    "        else:\n",
    "            i=3\n",
    "        arr = subject_dict_segments[subject][key]\n",
    "        \n",
    "        for n in np.unique(arr):\n",
    "            if microstate_rel_frequency[subject][i][n] == 0: \n",
    "                microstate_rel_frequency[subject][i][n] = (arr == n).sum()/len(arr)\n",
    "            else:\n",
    "                microstate_rel_frequency[subject][i][n] += (arr == n).sum()/len(arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92b73220",
   "metadata": {},
   "source": [
    "Visualizing the average durations of the 6 microstates across subjects for the different modes of thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_over_all_subjects = np.average(microstate_rel_frequency, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39acc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_over_all_subjects[1:, :] = mean_over_all_subjects[1:, :]/3 \n",
    "mean_over_all_subjects[0, :] = mean_over_all_subjects[0, :]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['Rest', 'Idea Generation', 'Idea Evolution', 'Evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca35cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ms in range(6):\n",
    "    plt.scatter(keys, mean_over_all_subjects[:, ms])\n",
    "    plt.title(f\"Microstate {ms+1}\")\n",
    "    plt.ylabel('Relative Frequency')\n",
    "    plt.show()\n",
    "    # plt.savefig('Microstate_' + str(ms+1) + '.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2621b91f",
   "metadata": {},
   "source": [
    "Plotting the microstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b46317",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = subject_dict_raw[0]['1_idea evolution']\n",
    "raw = mne.io.RawArray(arr, info = mne.create_info([str(i) for i in range(arr.shape[0])], 300, ch_types='eeg', verbose=None))\n",
    "maps, segmentation = mne_microstates.segment(raw.get_data(), n_states=6, verbose=0)\n",
    "mne_microstates.plot_segmentation(segmentation[:600],raw.get_data()[:, :600], raw.times[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(raw.times[:600], raw.get_data()[1, :600] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0ea2617",
   "metadata": {},
   "source": [
    "Training a model to only use the microstate features to predict mode of thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = microstate_rel_frequency.reshape((112,6))\n",
    "y = keys * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "svm = SVC(C=.20)\n",
    "svm = MLPClassifier((20, 50, 65, 20,), max_iter=1000, verbose=False)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0bdaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = svm.predict(X_test)\n",
    "accuracy = (preds==y_test).sum()/len(preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff00a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=svm.classes_)\n",
    "disp.plot()\n",
    "plt.savefig('confusion_matrix_just_microstate.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4816e408",
   "metadata": {},
   "source": [
    "### Adding Frequency Domain Features (Upper and Lower Alpha Band Power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ef0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6803750",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = subject_dict_raw[0]['1_idea generation'][0]\n",
    "sampling_frequency = 300\n",
    "time = np.arange(sig.size) / sampling_frequency\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,4))\n",
    "plt.plot(time, sig, lw=1.5, color='k')\n",
    "plt.xlabel('Time (Seconds)')\n",
    "plt.ylabel('Voltage')\n",
    "plt.xlim([time.min(), time.max()])\n",
    "plt.title('Single Channel EEG Data')\n",
    "sns.despine()\n",
    "# plt.plot([i for i in range(sig[0].size)], sig[0], color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "size = len(sig)\n",
    "fs = 300\n",
    "\n",
    "F, PSD = signal.welch(sig, fs, nperseg=size)\n",
    "plt.plot(F,PSD, color='k')\n",
    "plt.title(\"Welch's Periodogram\")\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power [$\\mu V^2$/Hz]')\n",
    "# plt.ylim([0,40])\n",
    "plt.xlim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "low, high = 8, 10\n",
    "\n",
    "# Find intersecting values in frequency vector\n",
    "idx_alpha = np.logical_and(F >= low, F <= high)\n",
    "\n",
    "# Plot the power spectral density and fill the delta area\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(F, PSD, lw=2, color='k')\n",
    "plt.fill_between(F, PSD, where=idx_alpha, color='skyblue')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power spectral density (uV^2 / Hz)')\n",
    "plt.xlim([6, 14])\n",
    "# plt.ylim([0, PSD.max() * 1.1])\n",
    "plt.ylim([0,.1e-5])\n",
    "plt.title(\"Welch's Periodogram\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "\n",
    "# Frequency resolution\n",
    "freq_res = F[1] - F[0]\n",
    "\n",
    "# Compute the absolute power by approximating the area under the curve\n",
    "alpha_power = simps(PSD[idx_alpha], dx=freq_res)\n",
    "print('Absolute lower alpha power: %.10f uV^2' % alpha_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dict_raw[0]['1_idea evolution'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trp_alpha = np.zeros((28, 4, 2, 1))\n",
    "\n",
    "for subject in list(subject_dict_raw.keys()):\n",
    "    curr_subject = subject_dict_raw[subject]\n",
    "    for key in list(curr_subject.keys()):\n",
    "        if 'rest' in key:\n",
    "            i=0\n",
    "        elif 'idea generation' in key:\n",
    "            i=1\n",
    "        elif 'evolution' in key:\n",
    "            i=2\n",
    "        else:\n",
    "            i=3\n",
    "        sig = curr_subject[key]\n",
    "        sig = np.mean(arr, axis=0)\n",
    "        size = len(sig)\n",
    "        fs = 300\n",
    "        F, PSD = signal.welch(sig, fs, nperseg=size)\n",
    "        \n",
    "        low, high = 8, 10\n",
    "        # Find intersecting values in frequency vector\n",
    "        idx_lower_alpha = np.logical_and(F >= low, F <= high)\n",
    "        req_res = F[1] - F[0]\n",
    "        lower_alpha_power = simps(PSD[idx_lower_alpha], dx=freq_res)\n",
    "        trp_alpha[subject][i][0] = lower_alpha_power\n",
    "        \n",
    "        low, high = 10, 12\n",
    "        # Find intersecting values in frequency vector\n",
    "        idx_upper_alpha = np.logical_and(F >= low, F <= high)\n",
    "        req_res = F[1] - F[0]\n",
    "        upper_alpha_power = simps(PSD[idx_upper_alpha], dx=freq_res)        \n",
    "        trp_alpha[subject][i][1] = upper_alpha_power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfada7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trp_alpha_all_channels = np.zeros((28, 63, 4, 2, 1))\n",
    "\n",
    "for subject in list(subject_dict_raw.keys()):\n",
    "    curr_subject = subject_dict_raw[subject]\n",
    "    for key in list(curr_subject.keys()):\n",
    "        if 'rest' in key:\n",
    "            i=0\n",
    "        elif 'idea generation' in key:\n",
    "            i=1\n",
    "        elif 'evolution' in key:\n",
    "            i=2\n",
    "        else:\n",
    "            i=3\n",
    "        sig = curr_subject[key]\n",
    "#         sig = np.mean(arr, axis=0)\n",
    "        for channel in range(sig.shape[0]):\n",
    "            curr = sig[channel]\n",
    "            size = len(curr)\n",
    "            fs = 300\n",
    "            F, PSD = signal.welch(curr, fs, nperseg=size)\n",
    "\n",
    "            low, high = 8, 10\n",
    "            # Find intersecting values in frequency vector\n",
    "            idx_lower_alpha = np.logical_and(F >= low, F <= high)\n",
    "            req_res = F[1] - F[0]\n",
    "            lower_alpha_power = simps(PSD[idx_lower_alpha], dx=freq_res)\n",
    "            trp_alpha_all_channels[subject][channel][i][0] = lower_alpha_power\n",
    "\n",
    "            low, high = 10, 12\n",
    "            # Find intersecting values in frequency vector\n",
    "            idx_upper_alpha = np.logical_and(F >= low, F <= high)\n",
    "            req_res = F[1] - F[0]\n",
    "            upper_alpha_power = simps(PSD[idx_upper_alpha], dx=freq_res)        \n",
    "            trp_alpha_all_channels[subject][channel][i][1] = upper_alpha_power "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3e7e4d0",
   "metadata": {},
   "source": [
    "Plotting the average trp alpha values across all subjects for the different modes of thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42640670",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_subject_alpha = np.average(trp_alpha, axis=0)\n",
    "across_subject_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95bfe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Absolute Lower and Upper Alpha Power')\n",
    "plt.ylabel('Absolute Power')\n",
    "plt.scatter(keys, mean_over_all_subjects[:, 0], color='blue', label='Average Lower Alpha Power')\n",
    "plt.scatter(keys, mean_over_all_subjects[:, 1], color='orange', label=\"Average Upper Alpha Power\")\n",
    "plt.legend()\n",
    "plt.savefig('alpha_power.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "trp_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ebe3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "microstate_rel_frequency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b44290",
   "metadata": {},
   "outputs": [],
   "source": [
    "microstate_and_alpha = np.append(microstate_rel_frequency, trp_alpha, axis=2).reshape(28,4,8,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fecd840",
   "metadata": {},
   "source": [
    "### Modeling with Microstate Features and Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc53e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = microstate_and_alpha.reshape((112,8))\n",
    "y = keys * 28\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc85a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "numeric_labels = []\n",
    "for lab in y:\n",
    "    if 'Evolution' in lab:\n",
    "        numeric_labels.append(0)\n",
    "    elif 'Generation' in lab:\n",
    "        numeric_labels.append(1)\n",
    "    elif 'Evaluation' in lab:\n",
    "        numeric_labels.append(2)\n",
    "    else:\n",
    "        numeric_labels.append(3)\n",
    "        \n",
    "y = to_categorical(numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.3, random_state=265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='tanh', input_shape=(8,)))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(128, activation='tanh'))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(256, activation='tanh'))\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=opt, loss='CategoricalCrossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 1000, batch_size=10, validation_data=(X_test, y_test), callbacks=[callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(loss)+1)\n",
    "plt.plot(epochs, loss, 'orange', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.legend()\n",
    "plt.savefig('network_loss_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32bba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "y = keys * 28\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.3, random_state=265)\n",
    "\n",
    "lr = SVC(C=100, max_iter=10000, kernel=\"poly\", degree=2, random_state=11)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a7257",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(X_test)\n",
    "accuracy = (preds==y_test).sum()/len(preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=svm.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, random_state=265)\n",
    "pca_results = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=pca_results[:,0], y=pca_results[:,1], hue=y)\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('PCA Representation of Data')\n",
    "plt.savefig('pca_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbeb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "svm_pca = SVC(C=100, random_state=265, kernel='poly', degree=4)\n",
    "svm_pca.fit(pca_results, y)\n",
    "plot_decision_regions(np.array(pca_results), y, axis=1, clf=svm_pca, legend=3)\n",
    "plt.title('SVM Polynomial Kernel Decision Boundary')\n",
    "plt.xlabel('PCA Dimension 1')\n",
    "plt.ylabel('PCA Dimension 2')\n",
    "plt.savefig('SVM_decision_boundary.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a46f2f9a",
   "metadata": {},
   "source": [
    "## Converting the EEG Signal to EEG Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def generate_spectrogram(data, sampling_frequency=300):\n",
    "    data = np.mean(data, axis=0)\n",
    "    f, t, Sxx = signal.spectrogram(\n",
    "        data,\n",
    "        fs=sampling_frequency,\n",
    "        nperseg=sampling_frequency,\n",
    "        noverlap=sampling_frequency*0.95,)    \n",
    "    plt.ylim([0,20])\n",
    "    plt.axis('off')\n",
    "    plt.pcolormesh(t, f, Sxx, cmap='viridis')\n",
    "    plt.savefig('temp', bbox_inches='tight', pad_inches=0)\n",
    "    img = cv2.imread('temp.png')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "spectrograms = []\n",
    "subjects = []\n",
    "\n",
    "for subject in list(subject_dict_raw.keys()):\n",
    "    curr_subject = subject_dict_raw[subject]\n",
    "    for key in list(curr_subject.keys()):\n",
    "        curr = curr_subject[key]\n",
    "        curr = np.array(curr)\n",
    "        for i in range(3600, curr.size, 3600):\n",
    "            clip = curr[:, i-3600:i]\n",
    "            if clip.shape[1] == 3600:\n",
    "                spect, shape = generate_spectrogram(clip)\n",
    "                spectrograms.append(spect)\n",
    "                if 'evolution' in key:\n",
    "                    labels.append(\"Idea Evolution\")\n",
    "                elif 'generation' in key:\n",
    "                    labels.append(\"Idea Gemeration\")\n",
    "                elif 'rating' in key:\n",
    "                    labels.append('Idea Evaluation')\n",
    "                else:\n",
    "                    labels.append('Rest')\n",
    "                subjects.append(subject)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(spectrograms)\n",
    "y = np.array(labels)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Spectrograms_new', X)\n",
    "# np.save('Labels_new', y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd7452a2",
   "metadata": {},
   "source": [
    "Creating the datasets and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac0c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a46602",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('Spectrograms.npy')\n",
    "y = np.load('Labels.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb3d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_labels = []\n",
    "for lab in y:\n",
    "    if 'Evolution' in lab:\n",
    "        numeric_labels.append(0)\n",
    "    elif 'Gemeration' in lab:\n",
    "        numeric_labels.append(1)\n",
    "    elif 'Evaluation' in lab:\n",
    "        numeric_labels.append(2)\n",
    "    else:\n",
    "        numeric_labels.append(3)\n",
    "\n",
    "y = np.array(numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f20b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = y==0\n",
    "generation = y==1\n",
    "evaluation = y==2\n",
    "rest = y==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a4cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_evolution = y[evolution]\n",
    "y_generation = y[generation]\n",
    "y_evaluation = y[evaluation]\n",
    "y_rest = y[rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc774b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_evolution = X[evolution]\n",
    "X_generation = X[generation]\n",
    "X_evalutation = X[evaluation]\n",
    "X_rest = X[rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c009065",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_sample = np.random.randint(0, len(y[evolution]), 600)\n",
    "generation_sample = np.random.randint(0, len(y[generation]), 600)\n",
    "evaluation_sample = np.random.randint(0, len(y[evaluation]), 600)\n",
    "rest_sample = np.random.randint(0, len(y[rest]), 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal_evolution = X_evolution[evolution_sample]\n",
    "y_bal_evolution = y_evolution[evolution_sample]\n",
    "\n",
    "X_bal_generation = X_generation[generation_sample]\n",
    "y_bal_generation = y_generation[generation_sample]\n",
    "\n",
    "X_bal_evaluation = X_evalutation[evaluation_sample]\n",
    "y_bal_evaluation = y_evaluation[evaluation_sample]\n",
    "\n",
    "X_bal_rest = X_rest[rest_sample]\n",
    "y_bal_rest = y_rest[rest_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced = np.concatenate([X_bal_evolution, X_bal_generation, X_bal_evaluation, X_bal_rest])\n",
    "y_balanced = np.concatenate([y_bal_evolution, y_bal_generation, y_bal_evaluation, y_bal_rest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_balanced = to_categorical(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_idx = np.random.randint(0, len(y_balanced), 300)\n",
    "validationX = X_balanced[validation_idx]\n",
    "validationY = y_balanced[validation_idx]\n",
    "trainX = np.delete(X_balanced, validation_idx, 0)\n",
    "trainY = np.delete(y_balanced, validation_idx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(trainY, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7c939a6",
   "metadata": {},
   "source": [
    "Defining our Convolutional Neural Network Model to Process the Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb9b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, 3, activation='relu', padding='same' ,input_shape=(217, 334, 3)))\n",
    "model.add(Conv2D(16, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(3))\n",
    "model.add(Conv2D(32, 3, activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c39894",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c2da2f",
   "metadata": {},
   "source": [
    "Training the model and including data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0, horizontal_flip=True)\n",
    "it_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "steps = int(trainX.shape[0] / 64)\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "history = model.fit(it_train, steps_per_epoch=steps, epochs=200, validation_data=(validationX, validationY), callbacks=[callback, model_checkpoint_callback], verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc4550af",
   "metadata": {},
   "source": [
    "Plotting loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5adf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'][1:], color='blue', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'][1:], color='orange', label='Validation Loss')\n",
    "plt.title('CNN Loss History')\n",
    "plt.legend()\n",
    "plt.savefig('CNN loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84356a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'], color='blue', label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('CNN Accuracy History')\n",
    "plt.legend()\n",
    "plt.savefig('CNN Accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8944c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(validationX, validationY, verbose=0)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f30b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(validationX)\n",
    "preds = np.argmax(preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e97745",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth= np.argmax(validationY, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edfedbc7",
   "metadata": {},
   "source": [
    "Displaying a confusion matrrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ad4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(truth, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(cm, display_labels=['Idea Evolution', 'Idea Generation', 'Idea Evaluation', 'Rest'])\n",
    "disp.plot()\n",
    "plt.savefig('CNN Spectrogram Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d77f5",
   "metadata": {},
   "source": [
    "## 1D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819eb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 3, activation='relu', padding='same', input_shape=(217, 334, 3)))\n",
    "model.add(MaxPooling2D(3))\n",
    "model.add(Conv2D(16, 3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "opt = Adam(learning_rate=.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a6d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0, horizontal_flip=True)\n",
    "it_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "steps = int(trainX.shape[0] / 64)\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "history = model.fit(it_train, steps_per_epoch=steps, epochs=200, validation_data=(validationX, validationY), callbacks=[callback, model_checkpoint_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505821de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'][1:], color='blue', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'][1:], color='orange', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('CNN 1D Loss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adfa126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'], color='blue', label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('CNN 1D Accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(validationX, validationY, verbose=0)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(validationX)\n",
    "preds = np.argmax(preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth= np.argmax(validationY, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264918a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(truth, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(cm, display_labels=['Idea Evolution', 'Idea Generation', 'Idea Evaluation', 'Rest'])\n",
    "disp.plot()\n",
    "plt.savefig('CNN Spectrogram Test Confusion Matrix')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09428e5c",
   "metadata": {},
   "source": [
    "### Using GradCAM to Visualize Parts of the Spectrograms that Contribute to the Prediction of each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c445388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=1):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad105472",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = preprocess_input(get_img_array('temp.png', size=(217, 334, 3)))\n",
    "\n",
    "heatmap = make_gradcam_heatmap(img_array, model, 'conv2d_23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(heatmap)\n",
    "plt.axis('off')\n",
    "plt.savefig('Gradcam Idea Generation', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.3):\n",
    "    # Load the original image\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam('temp.png', heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c4c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(trainX[200:202])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841bba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY[200:202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8991924",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(dat[0].size) / 300\n",
    "plt.plot(time, dat[0])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.savefig('signal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a663bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.array(data['1_idea generation'])[:, :3600]\n",
    "generate_spectrogram(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
